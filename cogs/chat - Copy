import nextcord
from nextcord.ext import commands
import openai
from textblob import TextBlob
import httpx
import os
import tempfile
import base64
import re
import asyncio
import logging
import io
import aiohttp
from typing import Optional

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Load API key from environment variables
openai_api_key = os.getenv('OPENAI_API_KEY')
if not openai_api_key:
    raise ValueError("OPENAI_API_KEY environment variable not set")

# Initialize OpenAI client
openai.api_key = openai_api_key

# In-memory data structures to store user data
user_chat_histories = {}
user_latest_image_description = {}

def preprocess_text(text: str) -> str:
    """Preprocess input text."""
    return text.lower().strip()

async def fetch_url_content(url: str) -> str:
    """Fetch content from a URL."""
    try:
        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.get(url)
            response.raise_for_status()
            return response.text
    except Exception as e:
        logger.error("URL Fetch Exception: %s", e, exc_info=True)
        return f"An error occurred while fetching the URL: {e}"

async def chatbot(user_id: int, prompt: str, include_image_description: bool = False) -> str:
    """Generate a response using OpenAI API."""
    prompt = preprocess_text(prompt)

    if user_id not in user_chat_histories:
        user_chat_histories[user_id] = []

    if include_image_description and user_id in user_latest_image_description:
        context = user_latest_image_description[user_id]
        prompt = f"{context}\n{prompt}"

    user_chat_histories[user_id].append({"role": "user", "content": prompt})

    try:
        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {openai_api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "gpt-4o",
                    "messages": user_chat_histories[user_id],
                    "temperature": 0.7
                }
            )
        response.raise_for_status()
        response_json = response.json()
        response_text = response_json['choices'][0]['message']['content'].strip()
        user_chat_histories[user_id].append({"role": "assistant", "content": response_text})
    except Exception as e:
        logger.error("Chat API Exception: %s", e, exc_info=True)
        response_text = f"An error occurred: {e}"

    sentiment = TextBlob(response_text).sentiment.polarity
    if sentiment >= 0.5:
        personalized_response = " ðŸ˜Š"
    elif sentiment <= -0.5:
        personalized_response = " ðŸ˜Ÿ"
    else:
        personalized_response = " ðŸ™‚"
    return response_text + personalized_response

async def generate_chatgpt_response(style: str = "casual") -> str:
    """Generate a casual or funny response."""
    response_style_map = {
        "casual": ["That was a great idea for an image!", "Nice choice! I hope you like it.", "Here it is! Enjoy!"],
        "funny": ["Why did you make me do this?", "Really? This is what you wanted?", "Here it is! I hope it turned out well!"]
    }

    import random
    return random.choice(response_style_map.get(style, response_style_map["casual"]))

def encode_image(image_path: str) -> str:
    """Encode an image to base64."""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

async def analyze_image_request(image_url: str = None, base64_image: str = None) -> dict:
    """Analyze an image using OpenAI API."""
    try:
        content = [{"type": "text", "text": "Whatâ€™s in this image?"}]
        if image_url:
            content.append({"type": "image_url", "image_url": {"url": image_url}})
        elif base64_image:
            content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}})
        
        async with httpx.AsyncClient(timeout=30) as client:
            payload = {
                "model": "gpt-4o",
                "messages": [{"role": "user", "content": content}],
                "max_tokens": 300
            }
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {openai_api_key}"
            }
            response = await client.post("https://api.openai.com/v1/chat/completions", headers=headers, json=payload)
            response.raise_for_status()
            return response.json()
    except Exception as e:
        logger.error("Vision API Exception: %s", e, exc_info=True)
    return None

class Chat(commands.Cog):
    def __init__(self, bot):
        self.bot = bot

    @nextcord.slash_command(name="chat", description="Respond to a chat message using OpenAI or analyze an attached image.")
    async def chat(self, ctx: nextcord.Interaction, message: Optional[str] = None):
        await ctx.response.defer()
        user_id = ctx.user.id
        if ctx.data.get("attachments"):
            attachment = ctx.data["attachments"][0]
            with tempfile.TemporaryDirectory() as tmpdirname:
                image_path = os.path.join(tmpdirname, attachment.filename)
                await attachment.save(image_path)
                base64_image = encode_image(image_path)
                response_json = await analyze_image_request(base64_image=base64_image)
                if response_json and 'choices' in response_json:
                    response_text = response_json['choices'][0]['message']['content']
                    await ctx.send(response_text)
                    user_latest_image_description[user_id] = response_text
                else:
                    await ctx.send("Failed to process the image.")
        elif message:
            url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')
            url_match = url_pattern.search(message)
            include_image_description = user_id in user_latest_image_description

            if url_match:
                url = url_match.group(0)
                url_content = await fetch_url_content(url)
                message = f"{message}\n\nContent from the URL: {url_content}"
            
            chatbot_response = await chatbot(user_id, message, include_image_description)
            personalized_message = f"{ctx.user.display_name}, {chatbot_response}"
            for i in range(0, len(personalized_message), 2000):
                await ctx.send(personalized_message[i:i + 2000])
        else:
            await ctx.send("Please provide a message or attach an image.")

    @nextcord.slash_command(name="dalle", description="Generate an image using DALL-E. Provide a prompt for the image generation.")
    async def dalle(self, ctx: nextcord.Interaction, prompt: str):
        """Generate an image using DALL-E. Provide a prompt for the image generation.
        
        Example:
        ?dalle A futuristic city skyline at sunset
        """
        await ctx.response.defer()
        username = ctx.user.display_name

        size = "1792x1024"
        quality = "hd"
        
        size_match = re.search(r"size=(1024x1024|1024x1792|1792x1024)", prompt)
        quality_match = re.search(r"quality=(standard|hd)", prompt)
        
        if size_match:
            size = size_match.group(1)
            prompt = re.sub(r"size=(1024x1024|1024x1792|1792x1024)", "", prompt).strip()
        
        if quality_match:
            quality = quality_match.group(1)
            prompt = re.sub(r"quality=(standard|hd)", "", prompt).strip()
        
        retries = 3
        for attempt in range(retries):
            try:
                response = openai.Image.create(
                    model="dall-e-3",
                    prompt=prompt,
                    size=size,
                    quality=quality,
                    n=1,
                )
                if response:
                    image_url = response.data[0].url
                    logger.debug(f"Generated image URL: {image_url}")
                    
                    async with aiohttp.ClientSession() as session:
                        async with session.get(image_url) as resp:
                            if resp.status != 200:
                                await ctx.send(f'{username}, could not download file...')
                            else:
                                data = io.BytesIO(await resp.read())
                                await ctx.send(file=nextcord.File(data, 'dalle_image.png'))
                                
                                gpt_response = await generate_chatgpt_response(style="funny")
                                await ctx.send(f"{username}, here is your generated image! {gpt_response}")
                    return
            except openai.error.InvalidRequestError as e:
                if e.code == 'content_policy_violation':
                    await ctx.send(f"{username}, your prompt was rejected due to a content policy violation. Please try again with a different prompt.")
                    logger.error(f"Content policy violation with prompt: {prompt}")
                    return
                logger.error(f"DALL-E API InvalidRequestError (attempt {attempt + 1}): {e}")
                await asyncio.sleep(2 ** attempt)
            except Exception as e:
                logger.error(f"DALL-E API Exception (attempt {attempt + 1}): {e}", exc_info=True)
                await asyncio.sleep(2 ** attempt)
        
        await ctx.send(f"{username}, an error occurred while generating the image. Please try again.")

def setup(bot):
    bot.add_cog(Chat(bot))
